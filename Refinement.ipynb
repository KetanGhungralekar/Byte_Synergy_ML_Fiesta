{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk 1 to ./transcriptions\\chunk_1.txt\n",
      "Saved chunk 2 to ./transcriptions\\chunk_2.txt\n",
      "Saved chunk 3 to ./transcriptions\\chunk_3.txt\n",
      "Saved chunk 4 to ./transcriptions\\chunk_4.txt\n",
      "Saved chunk 5 to ./transcriptions\\chunk_5.txt\n",
      "Saved chunk 6 to ./transcriptions\\chunk_6.txt\n",
      "Saved chunk 7 to ./transcriptions\\chunk_7.txt\n",
      "Saved chunk 8 to ./transcriptions\\chunk_8.txt\n",
      "Saved chunk 9 to ./transcriptions\\chunk_9.txt\n",
      "Saved chunk 10 to ./transcriptions\\chunk_10.txt\n",
      "Saved chunk 11 to ./transcriptions\\chunk_11.txt\n",
      "Saved chunk 12 to ./transcriptions\\chunk_12.txt\n",
      "Saved chunk 13 to ./transcriptions\\chunk_13.txt\n",
      "Saved chunk 14 to ./transcriptions\\chunk_14.txt\n",
      "Saved chunk 15 to ./transcriptions\\chunk_15.txt\n",
      "Saved chunk 16 to ./transcriptions\\chunk_16.txt\n",
      "Saved chunk 17 to ./transcriptions\\chunk_17.txt\n",
      "Saved chunk 18 to ./transcriptions\\chunk_18.txt\n",
      "Saved chunk 19 to ./transcriptions\\chunk_19.txt\n",
      "Saved chunk 20 to ./transcriptions\\chunk_20.txt\n",
      "Saved chunk 21 to ./transcriptions\\chunk_21.txt\n",
      "Saved chunk 22 to ./transcriptions\\chunk_22.txt\n",
      "Saved chunk 23 to ./transcriptions\\chunk_23.txt\n",
      "Saved chunk 24 to ./transcriptions\\chunk_24.txt\n",
      "Saved chunk 25 to ./transcriptions\\chunk_25.txt\n",
      "Saved chunk 26 to ./transcriptions\\chunk_26.txt\n",
      "Saved chunk 27 to ./transcriptions\\chunk_27.txt\n",
      "Saved chunk 28 to ./transcriptions\\chunk_28.txt\n",
      "Saved chunk 29 to ./transcriptions\\chunk_29.txt\n",
      "Saved chunk 30 to ./transcriptions\\chunk_30.txt\n",
      "Saved chunk 31 to ./transcriptions\\chunk_31.txt\n",
      "Saved chunk 32 to ./transcriptions\\chunk_32.txt\n",
      "Saved chunk 33 to ./transcriptions\\chunk_33.txt\n",
      "Saved chunk 34 to ./transcriptions\\chunk_34.txt\n",
      "Saved chunk 35 to ./transcriptions\\chunk_35.txt\n",
      "Saved chunk 36 to ./transcriptions\\chunk_36.txt\n",
      "Saved chunk 37 to ./transcriptions\\chunk_37.txt\n",
      "Saved chunk 38 to ./transcriptions\\chunk_38.txt\n",
      "Saved chunk 39 to ./transcriptions\\chunk_39.txt\n",
      "Saved chunk 40 to ./transcriptions\\chunk_40.txt\n",
      "Saved chunk 41 to ./transcriptions\\chunk_41.txt\n",
      "Saved chunk 42 to ./transcriptions\\chunk_42.txt\n",
      "Saved chunk 43 to ./transcriptions\\chunk_43.txt\n",
      "Saved chunk 44 to ./transcriptions\\chunk_44.txt\n",
      "Saved chunk 45 to ./transcriptions\\chunk_45.txt\n",
      "Saved chunk 46 to ./transcriptions\\chunk_46.txt\n",
      "Saved chunk 47 to ./transcriptions\\chunk_47.txt\n",
      "Saved chunk 48 to ./transcriptions\\chunk_48.txt\n",
      "Saved chunk 49 to ./transcriptions\\chunk_49.txt\n",
      "Saved chunk 50 to ./transcriptions\\chunk_50.txt\n",
      "Saved chunk 51 to ./transcriptions\\chunk_51.txt\n",
      "Saved chunk 52 to ./transcriptions\\chunk_52.txt\n",
      "Saved chunk 53 to ./transcriptions\\chunk_53.txt\n",
      "Saved chunk 54 to ./transcriptions\\chunk_54.txt\n",
      "Saved chunk 55 to ./transcriptions\\chunk_55.txt\n",
      "Saved chunk 56 to ./transcriptions\\chunk_56.txt\n",
      "Saved chunk 57 to ./transcriptions\\chunk_57.txt\n",
      "Saved chunk 58 to ./transcriptions\\chunk_58.txt\n",
      "Saved chunk 59 to ./transcriptions\\chunk_59.txt\n",
      "Saved chunk 60 to ./transcriptions\\chunk_60.txt\n",
      "Saved chunk 61 to ./transcriptions\\chunk_61.txt\n",
      "Saved chunk 62 to ./transcriptions\\chunk_62.txt\n",
      "Saved chunk 63 to ./transcriptions\\chunk_63.txt\n",
      "Saved chunk 64 to ./transcriptions\\chunk_64.txt\n",
      "Saved chunk 65 to ./transcriptions\\chunk_65.txt\n",
      "Saved chunk 66 to ./transcriptions\\chunk_66.txt\n",
      "Saved chunk 67 to ./transcriptions\\chunk_67.txt\n",
      "Saved chunk 68 to ./transcriptions\\chunk_68.txt\n",
      "Saved chunk 69 to ./transcriptions\\chunk_69.txt\n",
      "Saved chunk 70 to ./transcriptions\\chunk_70.txt\n",
      "Saved chunk 71 to ./transcriptions\\chunk_71.txt\n",
      "Saved chunk 72 to ./transcriptions\\chunk_72.txt\n",
      "Saved chunk 73 to ./transcriptions\\chunk_73.txt\n",
      "Saved chunk 74 to ./transcriptions\\chunk_74.txt\n",
      "Saved chunk 75 to ./transcriptions\\chunk_75.txt\n",
      "Saved chunk 76 to ./transcriptions\\chunk_76.txt\n",
      "Saved chunk 77 to ./transcriptions\\chunk_77.txt\n",
      "Saved chunk 78 to ./transcriptions\\chunk_78.txt\n",
      "Saved chunk 79 to ./transcriptions\\chunk_79.txt\n",
      "Saved chunk 80 to ./transcriptions\\chunk_80.txt\n",
      "Saved chunk 81 to ./transcriptions\\chunk_81.txt\n",
      "Saved chunk 82 to ./transcriptions\\chunk_82.txt\n",
      "Saved chunk 83 to ./transcriptions\\chunk_83.txt\n",
      "Saved chunk 84 to ./transcriptions\\chunk_84.txt\n",
      "Saved chunk 85 to ./transcriptions\\chunk_85.txt\n",
      "Saved chunk 86 to ./transcriptions\\chunk_86.txt\n",
      "Saved chunk 87 to ./transcriptions\\chunk_87.txt\n",
      "Saved chunk 88 to ./transcriptions\\chunk_88.txt\n",
      "Saved chunk 89 to ./transcriptions\\chunk_89.txt\n",
      "Saved chunk 90 to ./transcriptions\\chunk_90.txt\n",
      "Saved chunk 91 to ./transcriptions\\chunk_91.txt\n",
      "Saved chunk 92 to ./transcriptions\\chunk_92.txt\n",
      "Saved chunk 93 to ./transcriptions\\chunk_93.txt\n",
      "Saved chunk 94 to ./transcriptions\\chunk_94.txt\n",
      "Saved chunk 95 to ./transcriptions\\chunk_95.txt\n",
      "Saved chunk 96 to ./transcriptions\\chunk_96.txt\n",
      "Saved chunk 97 to ./transcriptions\\chunk_97.txt\n",
      "Saved chunk 98 to ./transcriptions\\chunk_98.txt\n",
      "Saved chunk 99 to ./transcriptions\\chunk_99.txt\n",
      "Saved chunk 100 to ./transcriptions\\chunk_100.txt\n",
      "Saved chunk 101 to ./transcriptions\\chunk_101.txt\n",
      "Saved chunk 102 to ./transcriptions\\chunk_102.txt\n",
      "Saved chunk 103 to ./transcriptions\\chunk_103.txt\n",
      "Saved chunk 104 to ./transcriptions\\chunk_104.txt\n",
      "Saved chunk 105 to ./transcriptions\\chunk_105.txt\n",
      "Saved chunk 106 to ./transcriptions\\chunk_106.txt\n",
      "Saved chunk 107 to ./transcriptions\\chunk_107.txt\n",
      "Saved chunk 108 to ./transcriptions\\chunk_108.txt\n",
      "Saved chunk 109 to ./transcriptions\\chunk_109.txt\n",
      "Saved chunk 110 to ./transcriptions\\chunk_110.txt\n",
      "Saved chunk 111 to ./transcriptions\\chunk_111.txt\n",
      "Saved chunk 112 to ./transcriptions\\chunk_112.txt\n",
      "Saved chunk 113 to ./transcriptions\\chunk_113.txt\n",
      "Saved chunk 114 to ./transcriptions\\chunk_114.txt\n",
      "Saved chunk 115 to ./transcriptions\\chunk_115.txt\n",
      "Saved chunk 116 to ./transcriptions\\chunk_116.txt\n",
      "Saved chunk 117 to ./transcriptions\\chunk_117.txt\n",
      "Saved chunk 118 to ./transcriptions\\chunk_118.txt\n",
      "Saved chunk 119 to ./transcriptions\\chunk_119.txt\n",
      "Saved chunk 120 to ./transcriptions\\chunk_120.txt\n",
      "Saved chunk 121 to ./transcriptions\\chunk_121.txt\n",
      "Saved chunk 122 to ./transcriptions\\chunk_122.txt\n",
      "Saved chunk 123 to ./transcriptions\\chunk_123.txt\n",
      "Saved chunk 124 to ./transcriptions\\chunk_124.txt\n",
      "Saved chunk 125 to ./transcriptions\\chunk_125.txt\n",
      "Saved chunk 126 to ./transcriptions\\chunk_126.txt\n",
      "Saved chunk 127 to ./transcriptions\\chunk_127.txt\n",
      "Saved chunk 128 to ./transcriptions\\chunk_128.txt\n",
      "Saved chunk 129 to ./transcriptions\\chunk_129.txt\n",
      "Saved chunk 130 to ./transcriptions\\chunk_130.txt\n",
      "Saved chunk 131 to ./transcriptions\\chunk_131.txt\n",
      "Saved chunk 132 to ./transcriptions\\chunk_132.txt\n",
      "Saved chunk 133 to ./transcriptions\\chunk_133.txt\n",
      "Saved chunk 134 to ./transcriptions\\chunk_134.txt\n",
      "Saved chunk 135 to ./transcriptions\\chunk_135.txt\n",
      "Saved chunk 136 to ./transcriptions\\chunk_136.txt\n",
      "Saved chunk 137 to ./transcriptions\\chunk_137.txt\n",
      "Saved chunk 138 to ./transcriptions\\chunk_138.txt\n",
      "Saved chunk 139 to ./transcriptions\\chunk_139.txt\n",
      "Saved chunk 140 to ./transcriptions\\chunk_140.txt\n",
      "Saved chunk 141 to ./transcriptions\\chunk_141.txt\n",
      "Saved chunk 142 to ./transcriptions\\chunk_142.txt\n",
      "Saved chunk 143 to ./transcriptions\\chunk_143.txt\n",
      "Saved chunk 144 to ./transcriptions\\chunk_144.txt\n",
      "Saved chunk 145 to ./transcriptions\\chunk_145.txt\n",
      "Saved chunk 146 to ./transcriptions\\chunk_146.txt\n",
      "Saved chunk 147 to ./transcriptions\\chunk_147.txt\n",
      "Saved chunk 148 to ./transcriptions\\chunk_148.txt\n",
      "Saved chunk 149 to ./transcriptions\\chunk_149.txt\n",
      "Saved chunk 150 to ./transcriptions\\chunk_150.txt\n",
      "Saved chunk 151 to ./transcriptions\\chunk_151.txt\n",
      "Saved chunk 152 to ./transcriptions\\chunk_152.txt\n",
      "Saved chunk 153 to ./transcriptions\\chunk_153.txt\n",
      "Saved chunk 154 to ./transcriptions\\chunk_154.txt\n",
      "Saved chunk 155 to ./transcriptions\\chunk_155.txt\n",
      "Saved chunk 156 to ./transcriptions\\chunk_156.txt\n",
      "Saved chunk 157 to ./transcriptions\\chunk_157.txt\n",
      "Saved chunk 158 to ./transcriptions\\chunk_158.txt\n",
      "Saved chunk 159 to ./transcriptions\\chunk_159.txt\n",
      "Saved chunk 160 to ./transcriptions\\chunk_160.txt\n",
      "Saved chunk 161 to ./transcriptions\\chunk_161.txt\n",
      "Saved chunk 162 to ./transcriptions\\chunk_162.txt\n",
      "Saved chunk 163 to ./transcriptions\\chunk_163.txt\n",
      "Saved chunk 164 to ./transcriptions\\chunk_164.txt\n",
      "Saved chunk 165 to ./transcriptions\\chunk_165.txt\n",
      "Saved chunk 166 to ./transcriptions\\chunk_166.txt\n",
      "Saved chunk 167 to ./transcriptions\\chunk_167.txt\n",
      "Saved chunk 168 to ./transcriptions\\chunk_168.txt\n",
      "Saved chunk 169 to ./transcriptions\\chunk_169.txt\n",
      "Saved chunk 170 to ./transcriptions\\chunk_170.txt\n",
      "Saved chunk 171 to ./transcriptions\\chunk_171.txt\n",
      "Saved chunk 172 to ./transcriptions\\chunk_172.txt\n",
      "Saved chunk 173 to ./transcriptions\\chunk_173.txt\n",
      "Saved chunk 174 to ./transcriptions\\chunk_174.txt\n",
      "Saved chunk 175 to ./transcriptions\\chunk_175.txt\n",
      "Saved chunk 176 to ./transcriptions\\chunk_176.txt\n",
      "Saved chunk 177 to ./transcriptions\\chunk_177.txt\n",
      "Saved chunk 178 to ./transcriptions\\chunk_178.txt\n",
      "Saved chunk 179 to ./transcriptions\\chunk_179.txt\n",
      "Saved chunk 180 to ./transcriptions\\chunk_180.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Read the content from the file\n",
    "file_path = './all_transcription.txt'\n",
    "output_dir = './transcriptions'\n",
    "chunk_size = 500  # Number of words per chunk, adjust as needed\n",
    "\n",
    "# Make sure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Read the entire content of the transcription file\n",
    "# Read the entire content of the transcription file with utf-8 encoding\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Split the text into words\n",
    "words = text.split()\n",
    "num_words = len(words)\n",
    "chunk_count = (num_words // chunk_size) + 1\n",
    "\n",
    "# Divide the text into chunks and save each chunk\n",
    "for i in range(chunk_count):\n",
    "    start = i * chunk_size\n",
    "    end = start + chunk_size\n",
    "    chunk_words = words[start:end]\n",
    "    \n",
    "    # Join words to make a chunk of text\n",
    "    chunk_text = ' '.join(chunk_words)\n",
    "    \n",
    "    # Save each chunk as a new file\n",
    "    chunk_file_path = os.path.join(output_dir, f'chunk_{i+1}.txt')\n",
    "    with open(chunk_file_path, 'w',encoding='utf-8') as chunk_file:\n",
    "        chunk_file.write(chunk_text)\n",
    "    \n",
    "    print(f'Saved chunk {i+1} to {chunk_file_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text completion and cleanup done! Check the 'completed_transcriptions' folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def move_until_period(current_chunk, next_chunk):\n",
    "    # Check if current chunk ends without a period\n",
    "    if not current_chunk.endswith('.'):\n",
    "        # Find the first period in the next chunk\n",
    "        period_index = next_chunk.find('.')\n",
    "        if period_index != -1:\n",
    "            # Move the content from the start of next_chunk up to and including the first period\n",
    "            additional_text = next_chunk[:period_index + 1]\n",
    "            # Append this to the current chunk and update next_chunk\n",
    "            current_chunk += additional_text\n",
    "            next_chunk = next_chunk[period_index + 1:].lstrip()  # Remove the moved part from next_chunk and strip leading whitespace\n",
    "    return current_chunk, next_chunk\n",
    "\n",
    "def complete_sentences(folder_path):\n",
    "    # Get a sorted list of all text files in the folder\n",
    "    chunk_files = sorted([f for f in os.listdir(folder_path) if f.endswith('.txt')])\n",
    "    \n",
    "    chunks = []\n",
    "    for file in chunk_files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        with open(file_path, 'r',encoding='utf-8') as f:\n",
    "            chunks.append(f.read().strip())\n",
    "    \n",
    "    completed_chunks = []\n",
    "    \n",
    "    # Process each chunk and move part of next chunk if needed\n",
    "    for i in range(len(chunks) - 1):\n",
    "        current_chunk = chunks[i]\n",
    "        next_chunk = chunks[i + 1]\n",
    "        \n",
    "        # Move part of next_chunk until the first period if current_chunk doesn't end with one\n",
    "        current_chunk, next_chunk = move_until_period(current_chunk, next_chunk)\n",
    "        \n",
    "        # Add the modified current_chunk to completed_chunks\n",
    "        completed_chunks.append(current_chunk)\n",
    "        \n",
    "        # Update the next chunk in the chunks list for the next iteration\n",
    "        chunks[i + 1] = next_chunk\n",
    "    \n",
    "    # Append the last chunk as it has no next chunk to compare\n",
    "    completed_chunks.append(chunks[-1])\n",
    "    \n",
    "    # Write the completed text back to files in a new folder 'completed_transcriptions'\n",
    "    output_folder = os.path.join(\"./Refined\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    for idx, text in enumerate(completed_chunks):\n",
    "        output_file = os.path.join(output_folder, f'completed_chunk_{idx+1}.txt')\n",
    "        with open(output_file, 'w',encoding='utf-8') as f:\n",
    "            f.write(text)\n",
    "    \n",
    "    print(\"Text completion and cleanup done! Check the 'completed_transcriptions' folder.\")\n",
    "\n",
    "# Folder path containing transcription files\n",
    "folder_path = \"transcriptions\"\n",
    "complete_sentences(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refinement done! Check the 'refined_transcriptions' folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# Set up OpenAI API with your credentials\n",
    "openai.api_key = \"pk-XaEUxTeyesYpIltKXeimYKZjDYJhrfWyoKXRwITKKYAhfrJt\"\n",
    "openai.base_url = \"https://api.pawan.krd/pai-001/v1/\"\n",
    "\n",
    "def refine_text(text):\n",
    "    # Call the OpenAI API to refine each chunk of text\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"Please summarize the following paragraph into a concise paragraph that includes all essential details, including key statistics and numbers. The output should be refined plain text only. It should contain all inportant details in it , Here is the paragraph:'{text}'\"},\n",
    "        ],\n",
    "    )\n",
    "    # Extract the refined text from the API response\n",
    "    refined_text = response.choices[0].message.content\n",
    "    return refined_text\n",
    "\n",
    "\n",
    "def refine_completed_files(folder_path):\n",
    "    # Path to folder containing completed text files\n",
    "    completed_folder = os.path.join(\"./Refined\")\n",
    "    refined_folder = os.path.join(\"./Final_confirm\")\n",
    "    \n",
    "    # Ensure the refined folder exists\n",
    "    os.makedirs(refined_folder, exist_ok=True)\n",
    "    \n",
    "    # Process each completed file in the folder\n",
    "    for file_name in sorted(os.listdir(completed_folder)):\n",
    "        if file_name.endswith('.txt'):\n",
    "            # Read the content of each completed file\n",
    "            file_path = os.path.join(completed_folder, file_name)\n",
    "            with open(file_path, 'r' ,encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "            \n",
    "            # Refine the content using OpenAI API\n",
    "            refined_content = refine_text(content)\n",
    "            \n",
    "            # Write the refined content to a new file in the refined folder\n",
    "            refined_file_path = os.path.join(refined_folder, f'refined_{file_name}')\n",
    "            with open(refined_file_path, 'w',encoding='utf-8') as refined_file:\n",
    "                refined_file.write(refined_content)\n",
    "    \n",
    "    print(\"Refinement done! Check the 'refined_transcriptions' folder.\")\n",
    "\n",
    "# Folder path containing the 'completed_transcriptions' folder\n",
    "folder_path = \"transcriptions\"\n",
    "refine_completed_files(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files combined into ./final_combined_output.txt.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def combine_files(input_folder, output_file):\n",
    "    # Open the output file in write mode\n",
    "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        # Iterate through each file in the input folder\n",
    "        for file_name in sorted(os.listdir(input_folder)):\n",
    "            if file_name.endswith('.txt'):\n",
    "                file_path = os.path.join(input_folder, file_name)\n",
    "                # Read content from each file and write to the output file\n",
    "                with open(file_path, 'r', encoding='utf-8') as infile:\n",
    "                    outfile.write(infile.read() + \"\\n\\n\")  # Add separation between files\n",
    "    print(f\"All files combined into {output_file}.\")\n",
    "\n",
    "# Define the folder containing refined text files and the output file name\n",
    "input_folder = \"./Final_confirm\"\n",
    "output_file = \"./final_combined_output.txt\"\n",
    "\n",
    "combine_files(input_folder, output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
